{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "oswTSQ5m64sK",
        "AZIMEmgE-UHv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Dummy example - Working smoothly"
      ],
      "metadata": {
        "id": "-eWSLGvw6uq0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUeCYILkWDys",
        "outputId": "18eb3d2b-5abb-4325-fd3f-2e5a557b6f27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=769217ee1e83a63c3426292f12302f40ce9c0432f83a132d69ac072aacc4814d\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphframes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeCr8pfFWGcl",
        "outputId": "acef1129-413e-459b-a15d-c937ea719b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting graphframes\n",
            "  Downloading graphframes-0.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from graphframes) (1.25.2)\n",
            "Collecting nose (from graphframes)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nose, graphframes\n",
            "Successfully installed graphframes-0.6 nose-1.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from graphframes import GraphFrame\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"GraphFramesExample\") \\\n",
        "    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.0-s_2.12\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "GfZ4Gzt2WJL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Create a sample GraphFrame\n",
        "    vertices = spark.createDataFrame([\n",
        "        (\"A\", \"Alice\", 34),\n",
        "        (\"B\", \"Bob\", 36),\n",
        "        (\"C\", \"Charlie\", 30),\n",
        "    ], [\"id\", \"name\", \"age\"])\n",
        "\n",
        "    edges = spark.createDataFrame([\n",
        "        (\"A\", \"B\", \"friend\"),\n",
        "        (\"B\", \"C\", \"follow\"),\n",
        "        (\"C\", \"A\", \"friend\"),\n",
        "    ], [\"src\", \"dst\", \"relationship\"])\n",
        "\n",
        "    graph = GraphFrame(vertices, edges)\n",
        "\n",
        "    # Print vertices and edges to verify they are correctly loaded\n",
        "    print(\"Vertices:\")\n",
        "    graph.vertices.show()\n",
        "\n",
        "    print(\"Edges:\")\n",
        "    graph.edges.show()\n",
        "\n",
        "    # Query: Get all the vertices where age > 30\n",
        "    filtered_vertices = graph.vertices.filter(\"age > 30\")\n",
        "    print(\"Vertices with age > 30:\")\n",
        "    filtered_vertices.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "finally:\n",
        "    # Stop SparkSession\n",
        "    spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lma8RzTm5hXO",
        "outputId": "e94fd68b-ab3c-4b83-e70a-faa27f0b6fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vertices:\n",
            "+---+-------+---+\n",
            "| id|   name|age|\n",
            "+---+-------+---+\n",
            "|  A|  Alice| 34|\n",
            "|  B|    Bob| 36|\n",
            "|  C|Charlie| 30|\n",
            "+---+-------+---+\n",
            "\n",
            "Edges:\n",
            "+---+---+------------+\n",
            "|src|dst|relationship|\n",
            "+---+---+------------+\n",
            "|  A|  B|      friend|\n",
            "|  B|  C|      follow|\n",
            "|  C|  A|      friend|\n",
            "+---+---+------------+\n",
            "\n",
            "Vertices with age > 30:\n",
            "+---+-----+---+\n",
            "| id| name|age|\n",
            "+---+-----+---+\n",
            "|  A|Alice| 34|\n",
            "|  B|  Bob| 36|\n",
            "+---+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Trying out something new"
      ],
      "metadata": {
        "id": "l92tb6aa0Gak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "34QGNTWy0GDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wZzaDmjn0F4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yf3FSNKz0FtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0OLNfXDG0Fh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Y-SQPnH0FYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F3C1rbz-0E6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mtqlIxIw0G_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cliques - K:3"
      ],
      "metadata": {
        "id": "oswTSQ5m64sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NShx7ebZ7Q7l",
        "outputId": "fad06966-b746-4d8c-c04f-6f587908a758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from graphframes import GraphFrame\n",
        "\n",
        "# Initialize Spark session with GraphFrames package\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"FindCliques\") \\\n",
        "    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.0-s_2.12\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load the edgelist CSV file into a DataFrame\n",
        "edgelist_df = spark.read.csv(\"/content/weighted_edges.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# # Assume the CSV has columns 'Source', 'Target', and 'Weight'\n",
        "vertices_df = edgelist_df.select(col(\"Source\").alias(\"id\")).union(edgelist_df.select(col(\"Target\").alias(\"id\"))).distinct()\n",
        "edges_df = edgelist_df.select(col(\"Source\").alias(\"src\"), col(\"Target\").alias(\"dst\"), col(\"Weight\"))\n",
        "\n",
        "# # Create a GraphFrame\n",
        "g = GraphFrame(vertices_df, edges_df)\n",
        "\n",
        "# Find cliques (using maximal clique algorithm from GraphFrames)\n",
        "# This example will find 3-cliques (triangles)\n",
        "cliques = g.find(\"(a)-[]->(b); (a)-[]->(c); (b)-[]->(c)\")\n",
        "\n",
        "# Show the cliques\n",
        "cliques.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5IvYSmg6-kj",
        "outputId": "840308de-8cad-49bf-b4f7-90b8b567b968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
            "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+------+\n",
            "|    a|     b|     c|\n",
            "+-----+------+------+\n",
            "|{148}|{2876}|{5127}|\n",
            "|{148}|{2876}|{3890}|\n",
            "|{148}|{2876}|{4998}|\n",
            "|{148}|{2876}|{3614}|\n",
            "|{148}|{2876}|{3848}|\n",
            "|{148}|{2876}|{4145}|\n",
            "|{148}|{3890}|{5127}|\n",
            "|{148}|{3890}|{4145}|\n",
            "|{148}|{3890}|{4022}|\n",
            "|{148}|{2054}|{5127}|\n",
            "|{148}|{2054}|{2876}|\n",
            "|{148}|{2054}|{3890}|\n",
            "|{148}|{2054}|{4998}|\n",
            "|{148}|{2054}|{2537}|\n",
            "|{148}|{2054}|{3614}|\n",
            "|{148}|{2054}|{3848}|\n",
            "|{148}|{2054}|{2813}|\n",
            "|{148}|{2054}|{4145}|\n",
            "|{148}|{2054}|{2308}|\n",
            "|{148}|{2054}|{4022}|\n",
            "+-----+------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cliques.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxY-Gq-mr3Xr",
        "outputId": "e3610c79-b0f3-45b3-8652-95d8f820819e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8867535"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cliques - K:4"
      ],
      "metadata": {
        "id": "AZIMEmgE-UHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from graphframes import GraphFrame\n",
        "\n",
        "# Initialize Spark session with GraphFrames package\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"FindCliques\") \\\n",
        "    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.0-s_2.12\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load the edgelist CSV file into a DataFrame\n",
        "edgelist_df = spark.read.csv(\"/content/weighted_edges.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# # Assume the CSV has columns 'Source', 'Target', and 'Weight'\n",
        "vertices_df = edgelist_df.select(col(\"Source\").alias(\"id\")).union(edgelist_df.select(col(\"Target\").alias(\"id\"))).distinct()\n",
        "edges_df = edgelist_df.select(col(\"Source\").alias(\"src\"), col(\"Target\").alias(\"dst\"), col(\"Weight\"))\n",
        "\n",
        "# # Create a GraphFrame\n",
        "g = GraphFrame(vertices_df, edges_df)\n",
        "\n",
        "# Find cliques (using maximal clique algorithm from GraphFrames)\n",
        "# This example will find 4-cliques (triangles)\n",
        "cliques = g.find(\"(a)-[]->(b); (a)-[]->(c); (a)-[]->(d); (b)-[]->(c); (b)-[]->(d); (c)-[]->(d)\")\n",
        "\n",
        "# Show the cliques\n",
        "cliques.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddQFuBRP-jwm",
        "outputId": "632fda91-d61b-4ac6-ef02-95acaf1dd952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+------+------+\n",
            "|    a|     b|     c|     d|\n",
            "+-----+------+------+------+\n",
            "|{148}|{2876}|{3890}|{5127}|\n",
            "|{148}|{2876}|{3890}|{4145}|\n",
            "|{148}|{2876}|{3614}|{3890}|\n",
            "|{148}|{2876}|{3614}|{4998}|\n",
            "|{148}|{2876}|{3614}|{3848}|\n",
            "|{148}|{2876}|{3614}|{4145}|\n",
            "|{148}|{2876}|{3848}|{5127}|\n",
            "|{148}|{2876}|{3848}|{3890}|\n",
            "|{148}|{2876}|{3848}|{4998}|\n",
            "|{148}|{2876}|{3848}|{3848}|\n",
            "|{148}|{2876}|{3848}|{4145}|\n",
            "|{148}|{2876}|{4145}|{4998}|\n",
            "|{148}|{2876}|{4145}|{4145}|\n",
            "|{148}|{3890}|{4145}|{4145}|\n",
            "|{148}|{3890}|{4022}|{4145}|\n",
            "|{148}|{2054}|{2876}|{5127}|\n",
            "|{148}|{2054}|{2876}|{3890}|\n",
            "|{148}|{2054}|{2876}|{4998}|\n",
            "|{148}|{2054}|{2876}|{3614}|\n",
            "|{148}|{2054}|{2876}|{3848}|\n",
            "+-----+------+------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cliques.count()"
      ],
      "metadata": {
        "id": "prwiUxLMvevF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Clique\n",
        "\n"
      ],
      "metadata": {
        "id": "aJRbnrT2DZ_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from graphframes import GraphFrame\n",
        "\n",
        "# Initialize Spark session with GraphFrames package\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"FindCliques\") \\\n",
        "    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.0-s_2.12\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load the edgelist CSV file into a DataFrame\n",
        "edgelist_df = spark.read.csv(\"/content/weighted_edges.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# # Assume the CSV has columns 'Source', 'Target', and 'Weight'\n",
        "vertices_df = edgelist_df.select(col(\"Source\").alias(\"id\")).union(edgelist_df.select(col(\"Target\").alias(\"id\"))).distinct()\n",
        "edges_df = edgelist_df.select(col(\"Source\").alias(\"src\"), col(\"Target\").alias(\"dst\"), col(\"Weight\"))\n",
        "\n",
        "# # Create a GraphFrame\n",
        "g = GraphFrame(vertices_df, edges_df)\n",
        "\n",
        "# Find cliques (using maximal clique algorithm from GraphFrames)\n",
        "# This example will find 3-cliques (triangles)\n",
        "cliques = g.find(\"(a)-[]->(b); (a)-[]->(c); (b)-[]->(c)\")\n",
        "\n",
        "# Show the cliques\n",
        "cliques.show()"
      ],
      "metadata": {
        "id": "NOFxu58CHmYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f59f1b18-9378-46a1-9c0e-10c31a85651b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
            "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+------+\n",
            "|    a|     b|     c|\n",
            "+-----+------+------+\n",
            "|{148}|{2876}|{5127}|\n",
            "|{148}|{2876}|{3890}|\n",
            "|{148}|{2876}|{4998}|\n",
            "|{148}|{2876}|{3614}|\n",
            "|{148}|{2876}|{3848}|\n",
            "|{148}|{2876}|{4145}|\n",
            "|{148}|{3890}|{5127}|\n",
            "|{148}|{3890}|{4145}|\n",
            "|{148}|{3890}|{4022}|\n",
            "|{148}|{2054}|{5127}|\n",
            "|{148}|{2054}|{2876}|\n",
            "|{148}|{2054}|{3890}|\n",
            "|{148}|{2054}|{4998}|\n",
            "|{148}|{2054}|{2537}|\n",
            "|{148}|{2054}|{3614}|\n",
            "|{148}|{2054}|{3848}|\n",
            "|{148}|{2054}|{2813}|\n",
            "|{148}|{2054}|{4145}|\n",
            "|{148}|{2054}|{2308}|\n",
            "|{148}|{2054}|{4022}|\n",
            "+-----+------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label Propagation"
      ],
      "metadata": {
        "id": "8TTGliz9L-MU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "communities = g.labelPropagation(maxIter=1)"
      ],
      "metadata": {
        "id": "QzXboKdyHzC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b879c6c-5762-4097-ce6f-c6582353fe9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
            "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "communities.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elF3PeyWRSyW",
        "outputId": "d7698c5f-8100-420a-def0-25527588cf96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5255"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "communities.persist().show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMdHImxDM00-",
        "outputId": "f877e13e-a7d0-4d15-b2f0-a27ad85e84a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|  id|label|\n",
            "+----+-----+\n",
            "|3558|  182|\n",
            "|1084| 3322|\n",
            "|4685| 2766|\n",
            "|4904| 1160|\n",
            "|3702| 3044|\n",
            "|4551| 1115|\n",
            "|3007| 4551|\n",
            "| 667| 3026|\n",
            "|1053| 3753|\n",
            "|1894|  182|\n",
            "+----+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_label = 182\n",
        "\n",
        "same_community = communities.filter(communities.label == selected_label)\n",
        "\n",
        "# Displaying the nodes in the same community\n",
        "same_community.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq60OrAVPNIE",
        "outputId": "1267cb71-b647-4f3b-d936-a9484374c40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "same_community.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "KlYjFOVvPbDs",
        "outputId": "aaacc4cb-f877-41dc-e6e5-e25973d02dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'same_community' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-65286915a7ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msame_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'same_community' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_j0ErWOk6CE8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}